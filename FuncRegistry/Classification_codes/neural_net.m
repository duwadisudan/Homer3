% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 01-Apr-2024 16:27:04
%
% This script assumes these variables are defined:
%
%   featureVector_Tr - input data.
%   expandedLabels_Tr - target data.

function testAccuracy = neural_net(featureVector_Tr, expandedLabels_Tr, ...
    featureVector_Tst, expandedLabels_Tst)

x = featureVector_Tr';
t = expandedLabels_Tr';

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainscg';  % Scaled conjugate gradient backpropagation.

% Create a Pattern Recognition Network
hiddenLayerSize = 10;
net = patternnet(hiddenLayerSize, trainFcn);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 100/100;
% net.divideParam.valRatio = 15/100;
%net.divideParam.testRatio = 15/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'crossentropy';  % Cross Entropy

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
%net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    % 'plotconfusion', 'plotroc'};

% Train the Network
[net,tr] = train(net,x,t);

% Test the Network
y = net(x);
e = gsubtract(t,y);
performance = perform(net,t,y)
tind = vec2ind(t);
yind = vec2ind(y);
percentErrors = sum(tind ~= yind)/numel(tind);


predictedLabelsTrain = y > 0.5;  % Thresholding


% If your actual labels (tTest) are not binary (0 and 1), convert them first
actualLabelsTrain = t > 0.5;  % This step is necessary if tTest is not already binary

% Calculate accuracy
trainAccuracy = sum(predictedLabelsTrain == actualLabelsTrain) / numel(actualLabelsTrain);

% Display the test accuracy
fprintf('Test Accuracy: %.2f%%\n', trainAccuracy * 100);

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t .* tr.valMask{1};
testTargets = t .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y)
valPerformance = perform(net,valTargets,y)
testPerformance = perform(net,testTargets,y)

trainAccuracy = sum(yind == tind) / numel(tind);


% View the Network
%view(net)

% [Existing training script]

% Test the Network with new data
xTest = featureVector_Tst';
tTest = expandedLabels_Tst';

yTest = net(xTest);

predictedLabelsTest = yTest > 0.5;  % Thresholding


% If your actual labels (tTest) are not binary (0 and 1), convert them first
actualLabelsTest = tTest > 0.5;  % This step is necessary if tTest is not already binary

% Calculate accuracy
testAccuracy = sum(predictedLabelsTest == actualLabelsTest) / numel(actualLabelsTest);

% Display the test accuracy
fprintf('Test Accuracy: %.2f%%\n', testAccuracy * 100);

end
